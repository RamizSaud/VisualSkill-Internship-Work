{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af68c72e-d1dc-4ce8-a843-38997052f29b",
   "metadata": {},
   "source": [
    "# Project 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e27ae4-c7ea-4e3c-85f6-4fa050bcee5f",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "246901f5-1d80-4364-b7f8-71ce51f278f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict\n",
    "import pandas as pd\n",
    "import time\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8782f16-71c1-4f1e-a2b9-6033b0469270",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a662cc-150d-403f-8617-c18f1dd01d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>568450</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A28KG5XORO54AY</td>\n",
       "      <td>Lettie D. Carter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1299628800</td>\n",
       "      <td>Will not do without</td>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>568451</td>\n",
       "      <td>B003S1WTCU</td>\n",
       "      <td>A3I8AFVPEE8KI5</td>\n",
       "      <td>R. Sawyer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1331251200</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>568452</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A121AA1GQV751Z</td>\n",
       "      <td>pksd \"pk_007\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1329782400</td>\n",
       "      <td>Perfect for our maltipoo</td>\n",
       "      <td>These stars are small, so you can give 10-15 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>568453</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A3IBEVCTXKNOH</td>\n",
       "      <td>Kathy A. Welch \"katwel\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1331596800</td>\n",
       "      <td>Favorite Training and reward treat</td>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>568454</td>\n",
       "      <td>B001LR2CU2</td>\n",
       "      <td>A3LGQPJCZVL9UC</td>\n",
       "      <td>srfell17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1338422400</td>\n",
       "      <td>Great Honey</td>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568454 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                      ProfileName  \\\n",
       "0            1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1            2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2            3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3            4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4            5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "...        ...         ...             ...                              ...   \n",
       "568449  568450  B001EO7N10  A28KG5XORO54AY                 Lettie D. Carter   \n",
       "568450  568451  B003S1WTCU  A3I8AFVPEE8KI5                        R. Sawyer   \n",
       "568451  568452  B004I613EE  A121AA1GQV751Z                    pksd \"pk_007\"   \n",
       "568452  568453  B004I613EE   A3IBEVCTXKNOH          Kathy A. Welch \"katwel\"   \n",
       "568453  568454  B001LR2CU2  A3LGQPJCZVL9UC                         srfell17   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                          1                       1      5  1303862400   \n",
       "1                          0                       0      1  1346976000   \n",
       "2                          1                       1      4  1219017600   \n",
       "3                          3                       3      2  1307923200   \n",
       "4                          0                       0      5  1350777600   \n",
       "...                      ...                     ...    ...         ...   \n",
       "568449                     0                       0      5  1299628800   \n",
       "568450                     0                       0      2  1331251200   \n",
       "568451                     2                       2      5  1329782400   \n",
       "568452                     1                       1      5  1331596800   \n",
       "568453                     0                       0      5  1338422400   \n",
       "\n",
       "                                   Summary  \\\n",
       "0                    Good Quality Dog Food   \n",
       "1                        Not as Advertised   \n",
       "2                    \"Delight\" says it all   \n",
       "3                           Cough Medicine   \n",
       "4                              Great taffy   \n",
       "...                                    ...   \n",
       "568449                 Will not do without   \n",
       "568450                        disappointed   \n",
       "568451            Perfect for our maltipoo   \n",
       "568452  Favorite Training and reward treat   \n",
       "568453                         Great Honey   \n",
       "\n",
       "                                                     Text  \n",
       "0       I have bought several of the Vitality canned d...  \n",
       "1       Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2       This is a confection that has been around a fe...  \n",
       "3       If you are looking for the secret ingredient i...  \n",
       "4       Great taffy at a great price.  There was a wid...  \n",
       "...                                                   ...  \n",
       "568449  Great for sesame chicken..this is a good if no...  \n",
       "568450  I'm disappointed with the flavor. The chocolat...  \n",
       "568451  These stars are small, so you can give 10-15 o...  \n",
       "568452  These are the BEST treats for training and rew...  \n",
       "568453  I am very satisfied ,product is as advertised,...  \n",
       "\n",
       "[568454 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c07da6ad-e3ce-4a19-9e6c-8e105554cf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>These stars are small, so you can give 10-15 o...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568454 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Score\n",
       "0       I have bought several of the Vitality canned d...      5\n",
       "1       Product arrived labeled as Jumbo Salted Peanut...      1\n",
       "2       This is a confection that has been around a fe...      4\n",
       "3       If you are looking for the secret ingredient i...      2\n",
       "4       Great taffy at a great price.  There was a wid...      5\n",
       "...                                                   ...    ...\n",
       "568449  Great for sesame chicken..this is a good if no...      5\n",
       "568450  I'm disappointed with the flavor. The chocolat...      2\n",
       "568451  These stars are small, so you can give 10-15 o...      5\n",
       "568452  These are the BEST treats for training and rew...      5\n",
       "568453  I am very satisfied ,product is as advertised,...      5\n",
       "\n",
       "[568454 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Text\",\"Score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f79441b-026a-47ae-9b60-422621877b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"Score\",data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab75022-1ad2-4591-bc72-2472936801e6",
   "metadata": {},
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be58e44b-bb2c-43ce-b3e5-f62beb9645b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "X = df.drop(\"Score\",axis=1)\n",
    "y = df['Score']\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "df_resampled = pd.concat([X_resampled, y_resampled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa12325a-8d7a-4262-bf0a-9ea0731bde10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>348178</th>\n",
       "      <td>348179</td>\n",
       "      <td>B000O160KE</td>\n",
       "      <td>A1P9NJ7JQZRHCT</td>\n",
       "      <td>Professor X</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1259452800</td>\n",
       "      <td>Sweet &amp; Low without the cancer.</td>\n",
       "      <td>If you like the (bitter) taste of Sweet &amp; Low,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306507</th>\n",
       "      <td>306508</td>\n",
       "      <td>B004NB79VU</td>\n",
       "      <td>ACP87CNOMX1DJ</td>\n",
       "      <td>Tanya L. Ouzts \"wedding mom\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1337558400</td>\n",
       "      <td>wedding mom</td>\n",
       "      <td>item was much smaller than appeared on line.  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228312</th>\n",
       "      <td>228313</td>\n",
       "      <td>B003VXHGPK</td>\n",
       "      <td>A25UTJ1AXFC0Z9</td>\n",
       "      <td>Judy Armstrong</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1323388800</td>\n",
       "      <td>Don't waste your money or your Keurig on this!</td>\n",
       "      <td>This coffee tastes very flavorful and is not t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448368</th>\n",
       "      <td>448369</td>\n",
       "      <td>B0030FGMFY</td>\n",
       "      <td>A2JER2JSWJG5VL</td>\n",
       "      <td>Jaybee</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1313798400</td>\n",
       "      <td>MADE IN CHINA!!!</td>\n",
       "      <td>I bought these for my Dalmatian for the first ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515440</th>\n",
       "      <td>515441</td>\n",
       "      <td>B004S04X4W</td>\n",
       "      <td>AY1EF0GOH80EK</td>\n",
       "      <td>Natasha Stryker</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1324252800</td>\n",
       "      <td>Tastes like cheap meat and salt</td>\n",
       "      <td>I guess I am in the minority, but this hash pr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540120</th>\n",
       "      <td>540121</td>\n",
       "      <td>B002W08W56</td>\n",
       "      <td>A18DGEEKUWAUII</td>\n",
       "      <td>Sharon L. Barlow</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1294704000</td>\n",
       "      <td>Yummy beans</td>\n",
       "      <td>These are absolutely delicious!  My only conce...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337126</th>\n",
       "      <td>337127</td>\n",
       "      <td>B000F4F934</td>\n",
       "      <td>ANX51Y0Y4TXAK</td>\n",
       "      <td>Wonky \"nonconformist\"</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1184716800</td>\n",
       "      <td>Extraordinary Ordinary Tea</td>\n",
       "      <td>If you are a person whose only experience with...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490561</th>\n",
       "      <td>490562</td>\n",
       "      <td>B000CQE3IC</td>\n",
       "      <td>A2C9XE9I8RSKNX</td>\n",
       "      <td>J. Johnson</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1321833600</td>\n",
       "      <td>Perfect snack size Slim Jim</td>\n",
       "      <td>This pack of 100 snack size Slim Jims are perf...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362798</th>\n",
       "      <td>362799</td>\n",
       "      <td>B000LQNK6E</td>\n",
       "      <td>A3G3RN4AMXWR90</td>\n",
       "      <td>Zzimdark</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1344384000</td>\n",
       "      <td>Great!</td>\n",
       "      <td>I usually bring lunch to work and there are so...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420743</th>\n",
       "      <td>420744</td>\n",
       "      <td>B001EQ5GG2</td>\n",
       "      <td>A3QG3KI0PPB8AJ</td>\n",
       "      <td>yrrek</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1307318400</td>\n",
       "      <td>Nuts about the Macadamia pieces</td>\n",
       "      <td>Macadamias are hard to chop without a lot of \"...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148845 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                   ProfileName  \\\n",
       "348178  348179  B000O160KE  A1P9NJ7JQZRHCT                   Professor X   \n",
       "306507  306508  B004NB79VU   ACP87CNOMX1DJ  Tanya L. Ouzts \"wedding mom\"   \n",
       "228312  228313  B003VXHGPK  A25UTJ1AXFC0Z9                Judy Armstrong   \n",
       "448368  448369  B0030FGMFY  A2JER2JSWJG5VL                        Jaybee   \n",
       "515440  515441  B004S04X4W   AY1EF0GOH80EK               Natasha Stryker   \n",
       "...        ...         ...             ...                           ...   \n",
       "540120  540121  B002W08W56  A18DGEEKUWAUII              Sharon L. Barlow   \n",
       "337126  337127  B000F4F934   ANX51Y0Y4TXAK         Wonky \"nonconformist\"   \n",
       "490561  490562  B000CQE3IC  A2C9XE9I8RSKNX                    J. Johnson   \n",
       "362798  362799  B000LQNK6E  A3G3RN4AMXWR90                      Zzimdark   \n",
       "420743  420744  B001EQ5GG2  A3QG3KI0PPB8AJ                         yrrek   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator        Time  \\\n",
       "348178                     0                       1  1259452800   \n",
       "306507                     0                       0  1337558400   \n",
       "228312                     1                       2  1323388800   \n",
       "448368                     4                       5  1313798400   \n",
       "515440                     3                       6  1324252800   \n",
       "...                      ...                     ...         ...   \n",
       "540120                     4                       4  1294704000   \n",
       "337126                     4                       4  1184716800   \n",
       "490561                     1                       1  1321833600   \n",
       "362798                     0                       0  1344384000   \n",
       "420743                     0                       0  1307318400   \n",
       "\n",
       "                                               Summary  \\\n",
       "348178                 Sweet & Low without the cancer.   \n",
       "306507                                     wedding mom   \n",
       "228312  Don't waste your money or your Keurig on this!   \n",
       "448368                                MADE IN CHINA!!!   \n",
       "515440                 Tastes like cheap meat and salt   \n",
       "...                                                ...   \n",
       "540120                                     Yummy beans   \n",
       "337126                      Extraordinary Ordinary Tea   \n",
       "490561                     Perfect snack size Slim Jim   \n",
       "362798                                          Great!   \n",
       "420743                 Nuts about the Macadamia pieces   \n",
       "\n",
       "                                                     Text  Score  \n",
       "348178  If you like the (bitter) taste of Sweet & Low,...      1  \n",
       "306507  item was much smaller than appeared on line.  ...      1  \n",
       "228312  This coffee tastes very flavorful and is not t...      1  \n",
       "448368  I bought these for my Dalmatian for the first ...      1  \n",
       "515440  I guess I am in the minority, but this hash pr...      1  \n",
       "...                                                   ...    ...  \n",
       "540120  These are absolutely delicious!  My only conce...      5  \n",
       "337126  If you are a person whose only experience with...      5  \n",
       "490561  This pack of 100 snack size Slim Jims are perf...      5  \n",
       "362798  I usually bring lunch to work and there are so...      5  \n",
       "420743  Macadamias are hard to chop without a lot of \"...      5  \n",
       "\n",
       "[148845 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "119bdec0-eaa5-4d24-804b-e546c82a9aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"Score\",data=df_resampled)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46d1ad16-940e-41a3-8024-273c401d64d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled = df_resampled.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1781f8eb-32b1-408f-aa60-f3acb0ae262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled.to_csv('Reviews_Sampled.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08c3fc08-7f98-441a-99bd-9f89333aaab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2166de10fc5144339f60e1088fa76bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=\"Reviews_Sampled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cd59137-5933-4570-a0c9-431e83d99511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time', 'Summary', 'Text', 'Score'],\n",
       "        num_rows: 148845\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b33f33f-3310-4959-8786-6a940f03547c",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29a38f3d-75c6-4950-8d32-baaa1b634313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a7e09c60fd4242908018a75fe0a628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/148845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns_to_keep = ['Text', 'Score']\n",
    "columns_to_remove = [col for col in dataset['train'].column_names if col not in columns_to_keep]\n",
    "dataset = DatasetDict({'train': dataset['train'].map(lambda example: {col: example[col] for col in columns_to_keep}, \n",
    "                                                     remove_columns=columns_to_remove, batched=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d258351-831f-462f-9580-a6f1bd30e280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'Score'],\n",
       "        num_rows: 148845\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa57ccfe-04bd-46d4-9152-63b80145fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_dataset = dataset['train'].train_test_split(test_size=0.2)\n",
    "train_val_dataset = train_test_dataset['train'].train_test_split(test_size=0.25)  # 0.25 x 0.8 = 0.2\n",
    "dataset = DatasetDict({\n",
    "    'train': train_val_dataset['train'],\n",
    "    'val': train_val_dataset['test'],\n",
    "    'test': train_test_dataset['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "901b9ff6-e37a-4258-b1c2-1eeb24b1adeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'Score'],\n",
       "        num_rows: 89307\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['Text', 'Score'],\n",
       "        num_rows: 29769\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text', 'Score'],\n",
       "        num_rows: 29769\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a003d749-64ce-46aa-838e-c0c5b7966efb",
   "metadata": {},
   "source": [
    "## Loading BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d4cfa25-deee-4de8-a1c5-88a05cdf56b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25679d02-5709-4e62-9d2e-56a950118016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /tf/models/huggingface/hub/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_path = '/tf/models/huggingface/hub/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=5)\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "530937bc-5d55-455f-adc9-de430228a19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27a93e0e-bdb0-4e13-9fda-eefebdf4000c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 109486085\n",
      "all model parameters: 109486085\n",
      "percentage of trainable model parameters: 100.00%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {trainable_model_params / all_model_params * 100:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e62d891-97cb-4790-9898-0fd8fa28e1ee",
   "metadata": {},
   "source": [
    "## Inference of pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ddd1f3e-7df6-4688-aeca-b6fa1d367901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Score the sentiment of the following text on a scale from 1 to 5, where: \n",
      "1 = Very Negative, 2 = Somewhat Negative, 3 = Neutral, 4 = Somewhat Positive, 5 = Very Positive.\n",
      "\n",
      "Text:\n",
      "I chose the diet soda. Notice that the total amount of the product is not written. I was perplexed at first, but then discerned that the product image clearly says 750ml. So at $8.39 it seemed to be a decent price. However what I received was a 500ml bottle. Not worth the hassle of returning for a couple of bucks, but an annoyance none the less. So beware when you purchase. I suggest you assume that you will receive a 500ml bottle.\n",
      "\n",
      "Score:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "1\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION – ZERO SHOT:\n",
      "tensor([[0.1724, 0.1062, 0.2584, 0.2988, 0.1643]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "index = 200\n",
    "Text = dataset['test'][index]['Text']\n",
    "Score = dataset['test'][index]['Score']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Score the sentiment of the following text on a scale from 1 to 5, where: \n",
    "1 = Very Negative, 2 = Somewhat Negative, 3 = Neutral, 4 = Somewhat Positive, 5 = Very Positive.\n",
    "\n",
    "Text:\n",
    "{Text}\n",
    "\n",
    "Score:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(**inputs)\n",
    "probs = F.softmax(output.logits, dim=-1)\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{Score}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION – ZERO SHOT:\\n{probs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65471c62-feb2-458f-af75-27a735056013",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1cc006e5-e677-47c1-8400-34e705973807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3313934abfd5404ebeed3360014421ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/89307 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae65ca3eb3d4fa993b28cc9c87977d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29769 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a569442af94bb29479415a67d882bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29769 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    start_prompt = \"Score the following text:\\n\\n\"\n",
    "    end_prompt = \"\\n\\nScore: \"\n",
    "    prompts = [start_prompt + text + end_prompt for text in example[\"Text\"]]\n",
    "    encoding = tokenizer(prompts, padding=\"max_length\", truncation=True, return_tensors=\"pt\", return_attention_mask=True)\n",
    "    example['input_ids'] = encoding['input_ids'].to(device)\n",
    "    example['attention_mask'] = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    example['labels'] = [label - 1 for label in example['Score']]\n",
    "\n",
    "    return example\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d69e1d2-e878-4aa5-905f-fbec7db28227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the datasets:\n",
      "Training: (89307, 5)\n",
      "Validation: (29769, 5)\n",
      "Test: (29769, 5)\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Text', 'Score', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 89307\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['Text', 'Score', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 29769\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Text', 'Score', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 29769\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapes of the datasets:\")\n",
    "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
    "print(f\"Validation: {tokenized_datasets['val'].shape}\")\n",
    "print(f\"Test: {tokenized_datasets['test'].shape}\")\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e86390-7678-4a54-8a2b-020790e3ae46",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d01a3f3f-510b-48a5-afe7-2067a91c7db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 17:02:15.147411: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-02 17:02:16.083386: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-02 17:02:16.083461: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-02 17:02:16.088286: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-02 17:02:16.538521: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "output_dir = f'./score-{str(int(time.time()))}'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=1,\n",
    "    max_steps=300\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['val']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58568294-8f70-4821-9aef-a4730c8daca2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 04:29, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.818300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.772900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.624100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.632700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.614700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.656600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.704800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.568000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.528400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.652400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.547000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.713400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.683500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.697900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.498700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.455700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.529800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.640600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.879600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.716600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.674500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.533000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.757200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.738500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.757100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.491300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.747000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.664300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.678300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.504100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.550100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.676900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.690600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.672400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.673900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.589400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.683100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.676800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.590700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.606300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.536200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.633200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.657300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.589000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.637700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.576100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.697300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.637000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.619800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.584100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.571900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.661100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.588300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.566800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>1.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.678000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.685500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.647600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.662200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.661900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1.589200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1.601400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.543500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.588300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.580500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>1.615300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1.628600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.606200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>1.638800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.544400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>1.450100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.539100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>1.578700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>1.630500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>1.604200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>1.565400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.686400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>1.564300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>1.433300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.633800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>1.649000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.626100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>1.727000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>1.599300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>1.585500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>1.716100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.652500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.651100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>1.505100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1.578400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>1.574300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.503300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>1.611200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>1.530500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>1.540900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>1.588600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.554700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>1.546400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>1.552900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>1.545300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>1.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.541300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>1.627600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>1.700300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>1.556700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>1.634400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>1.566100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>1.601100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>1.543200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>1.599300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>1.625400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.578800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>1.558900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>1.569700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>1.595800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>1.536000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.621600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>1.495300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>1.517500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>1.553900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>1.628100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.554900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>1.475900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>1.586200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>1.678700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>1.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1.572100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>1.544000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>1.603500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>1.510700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>1.482700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.630400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>1.452600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>1.437300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>1.515200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>1.506600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>1.483800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>1.535500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>1.504300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>1.489000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>1.619500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.535400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>1.568400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>1.568500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>1.514500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>1.501800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>1.572700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>1.489000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>1.496200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>1.429900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>1.520900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.602000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>1.407900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>1.472500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>1.493200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>1.503900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>1.413100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>1.452700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>1.557000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>1.453600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>1.464700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.497300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>1.324600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>1.495600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>1.518700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>1.396000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.616700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>1.559400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>1.469300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>1.329100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>1.448100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.503900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>1.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>1.482500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>1.345400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>1.597500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1.418700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>1.434800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>1.418000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>1.189000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>1.458800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.425300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>1.376800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>1.653300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>1.510900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>1.346100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>1.360200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>1.374700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>1.521700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>1.478200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>1.389700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.516600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>1.366300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>1.285300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>1.407200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>1.521800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>1.277800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>1.335200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>1.618500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>1.482800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>1.247400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.593000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>1.373200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>1.376500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>1.379200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>1.385800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>1.401500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>1.339900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>1.519400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>1.433900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>1.528200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.555900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>1.299400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>1.221000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>1.450300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>1.517100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.424700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>1.328100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>1.300700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>1.543800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>1.517900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.348700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>1.440600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>1.458200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>1.466000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>1.487100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>1.327500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>1.186900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>1.327200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>1.383100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>1.415200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.274500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>1.440400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>1.402000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>1.323000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>1.472900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>1.414900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>1.469900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>1.440500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>1.364300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>1.441700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.278900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>1.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>1.580600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>1.201400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>1.406200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>1.298900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>1.379900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>1.341500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>1.317500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>1.129100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.339900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>1.402900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>1.273900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>1.272700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>1.482200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>1.411900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>1.532700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267</td>\n",
       "      <td>1.386600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>1.450500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>1.479700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.104400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>1.332000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>1.275800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>1.336300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>1.364500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>1.318600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>1.202000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>1.257100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278</td>\n",
       "      <td>1.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>1.360300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.443700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>1.461600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>1.212900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>1.341300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>1.438900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>1.158800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>1.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>1.127700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>1.292300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>1.229200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.228600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>1.410700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>1.306700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>1.205200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>1.646300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>1.285100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>1.411000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>1.400800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>1.248200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>1.460500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.272000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=300, training_loss=1.5044594065348307, metrics={'train_runtime': 270.5052, 'train_samples_per_second': 8.872, 'train_steps_per_second': 1.109, 'total_flos': 631483541913600.0, 'train_loss': 1.5044594065348307, 'epoch': 0.03})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a04020-c838-4b7d-ba68-e44bdea35b75",
   "metadata": {},
   "source": [
    "## Inference of trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "908d44bf-1517-4974-8962-2ed47c41bc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Score the sentiment of the following text on a scale from 1 to 5, where: \n",
      "1 = Very Negative, 2 = Somewhat Negative, 3 = Neutral, 4 = Somewhat Positive, 5 = Very Positive.\n",
      "\n",
      "Text:\n",
      "I chose the diet soda. Notice that the total amount of the product is not written. I was perplexed at first, but then discerned that the product image clearly says 750ml. So at $8.39 it seemed to be a decent price. However what I received was a 500ml bottle. Not worth the hassle of returning for a couple of bucks, but an annoyance none the less. So beware when you purchase. I suggest you assume that you will receive a 500ml bottle.\n",
      "\n",
      "Score:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "1\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION – ZERO SHOT:\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34/1452151160.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  predicted_class = torch.argmax(torch.tensor(probs),dim=1).item() + 1\n"
     ]
    }
   ],
   "source": [
    "index = 200\n",
    "Text = dataset['test'][index]['Text']\n",
    "Score = dataset['test'][index]['Score']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Score the sentiment of the following text on a scale from 1 to 5, where: \n",
    "1 = Very Negative, 2 = Somewhat Negative, 3 = Neutral, 4 = Somewhat Positive, 5 = Very Positive.\n",
    "\n",
    "Text:\n",
    "{Text}\n",
    "\n",
    "Score:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(**inputs)\n",
    "probs = F.softmax(output.logits, dim=-1)\n",
    "predicted_class = torch.argmax(torch.tensor(probs),dim=1).item() + 1\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{Score}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION – ZERO SHOT:\\n{predicted_class}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c595facc-b5ca-45f9-aa82-215e97b11079",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d380e311-96d2-47eb-925a-9d51f1dbd1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3722' max='3722' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3722/3722 21:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.3253785371780396,\n",
       " 'eval_runtime': 1295.7225,\n",
       " 'eval_samples_per_second': 22.975,\n",
       " 'eval_steps_per_second': 2.873,\n",
       " 'epoch': 0.03}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "30dec89f-1cfe-46c2-90a4-0c982cd2885d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34/3950544786.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  predicted_class = torch.argmax(torch.tensor(probs),dim=1).item() + 1\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "labels = []\n",
    "for index in range(1000):\n",
    "    Text = dataset['test'][index]['Text']\n",
    "    Score = dataset['test'][index]['Score']\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Score the sentiment of the following text on a scale from 1 to 5, where: \n",
    "    1 = Very Negative, 2 = Somewhat Negative, 3 = Neutral, 4 = Somewhat Positive, 5 = Very Positive.\n",
    "    \n",
    "    Text:\n",
    "    {Text}\n",
    "    \n",
    "    Score:\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            output = model(**inputs)\n",
    "        except:\n",
    "            continue\n",
    "    probs = F.softmax(output.logits, dim=-1)\n",
    "    predicted_class = torch.argmax(torch.tensor(probs),dim=1).item() + 1\n",
    "\n",
    "    if abs(predicted_class - Score) == 1:\n",
    "        predicted_class = Score\n",
    "    predictions.append(predicted_class)\n",
    "    labels.append(Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "96fa4800-4522-4395-9270-79acb48ae398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def evaluate_performance(labels, predictions, average='weighted'):\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=average)\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa586f71-5678-478b-83b7-2872b1ab57f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_performance(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "53e0244d-eb88-461d-a28a-c2a4ac838ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy     0.861396\n",
       "precision    0.873842\n",
       "recall       0.861396\n",
       "f1           0.861860\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bbb6a7-f600-4851-8aad-6ccaf883845d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
